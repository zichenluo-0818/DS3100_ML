{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DS 3001: Foundations of Machine Learning\n",
        "## Assignment 2: EDA/Visualization, KNN, K Means Clustering\n",
        "## (100 Possible Points)\n",
        "\n",
        "### **Your Name**: Last, First\n",
        "\n",
        "### **Your Computing ID:**\n",
        "\n",
        "### **Sign Honor Pledge Here:**\n",
        "\n",
        "On my honor as a student, I have neither given nor received unauthorized aid on this assignment.\n",
        "\n",
        "### **Assignment Description**\n",
        "\n",
        "The questions for the second assignment of the semester, `Assignment 2`, are found below. The questions are split between the topics we discussed in the EDA/Visualization, KNN, and K Means Clustering notebooks. These questions give you the chance to combine all that we've learned into tasks that you could run into as a data scientist.\n",
        "\n",
        "For help with formatting your markdown responses in text cells, reference this [markdown style cheat sheet](https://www.markdownguide.org/cheat-sheet/).\n",
        "\n",
        "**AI Use:** For Assignment 2, you may use autofill code suggestions that Google Colab provides to you in the code blocks. You should not assume that the suggestions are always correct. Make sure that you think critically about whether the suggestions are correct or not and if they make sense with what you are trying to achieve. You may NOT use AI for the written responses in the markdown cells. I want to know what you are thinking about for your justifications, not what an LLM produces. If you have any need for clarification on this policy, please reach out to me earlier than later.\n",
        "\n",
        "**Submission Instructions:** For a complete submission, please upload your completed Assignment 2 notebook (.ipynb) on Canvas.\n",
        "\n"
      ],
      "metadata": {
        "id": "hhApnPwhDZF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting up your directory"
      ],
      "metadata": {
        "id": "OGd6yEWiEY4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os # For changing directory\n",
        "\n",
        "# To mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yIXwgHd1EN5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee02fa26-fb01-4fb1-d060-c4fb6442f4a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_DS_3001_folder = '/content/drive/MyDrive/DS3001/assignments/'\n",
        "# path_to_DS_3001_folder = ''\n",
        "\n",
        "# Update the path to your folder for the class\n",
        "# Where you stored the data from the previous noteboook\n",
        "os.chdir(path_to_DS_3001_folder)"
      ],
      "metadata": {
        "id": "uhuysK0aEcfL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: EDA and Visualization (25 Points)"
      ],
      "metadata": {
        "id": "ydN2erobDtfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.1 (1 Point)**: Load in the `college_completion.csv` file using Pandas. You can find the file on the GitHub repository for class in the `assignments/data/` folder. This is a data set from the US Department of Education. We will look at the following variables:\n",
        "\n",
        "- `level`: Level of institution (4-year, 2-year).\n",
        "- `aid_value`: The average amount of student aid going to undergraduate recipients.\n",
        "- `control`: Public, Private not-for-profit, Private for-profit.\n",
        "- `grad_100_value`: percentage of first-time, full-time, degree-seeking undergraduates who complete a degree or certificate program within 100 percent of expected time (bachelor's-seeking group at 4-year institutions).\n",
        "\n"
      ],
      "metadata": {
        "id": "6wfincKHFbUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qxvYZZQ8DS0A"
      },
      "outputs": [],
      "source": [
        "# 1.1 Answer Here\n",
        "df = pd.read_csv('college_completion.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.2 (1 Point)**:\n",
        "  - What are are the dimensions of the data?\n",
        "  - How many observations are there? Save this values as a variable called n_rows and print to the screen.\n",
        "  - How many columns are there? Save this values as a variable called n_cols and print to the screen.\n",
        "  - Use `.head()` to examine the first few rows of data."
      ],
      "metadata": {
        "id": "1nGxFs6EGEoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Answer Here\n",
        "n_rows, n_cols = df.shape\n",
        "n_rows = {n_rows}\n",
        "n_cols = {n_cols}\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6wxeLxDgGsUG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "68694db4-9cbf-4b2b-afa7-36bcb7c860df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  unitid                            chronname        city    state  \\\n",
              "0      0  100654               Alabama A&M University      Normal  Alabama   \n",
              "1      1  100663  University of Alabama at Birmingham  Birmingham  Alabama   \n",
              "2      2  100690                   Amridge University  Montgomery  Alabama   \n",
              "3      3  100706  University of Alabama at Huntsville  Huntsville  Alabama   \n",
              "4      4  100724             Alabama State University  Montgomery  Alabama   \n",
              "\n",
              "    level                 control  \\\n",
              "0  4-year                  Public   \n",
              "1  4-year                  Public   \n",
              "2  4-year  Private not-for-profit   \n",
              "3  4-year                  Public   \n",
              "4  4-year                  Public   \n",
              "\n",
              "                                               basic hbcu flagship  ...  \\\n",
              "0  Masters Colleges and Universities--larger prog...    X      NaN  ...   \n",
              "1  Research Universities--very high research acti...  NaN      NaN  ...   \n",
              "2            Baccalaureate Colleges--Arts & Sciences  NaN      NaN  ...   \n",
              "3  Research Universities--very high research acti...  NaN      NaN  ...   \n",
              "4  Masters Colleges and Universities--larger prog...    X      NaN  ...   \n",
              "\n",
              "   vsa_grad_after6_transfer  vsa_grad_elsewhere_after6_transfer  \\\n",
              "0                      36.4                                 5.6   \n",
              "1                       NaN                                 NaN   \n",
              "2                       NaN                                 NaN   \n",
              "3                       0.0                                 0.0   \n",
              "4                       NaN                                 NaN   \n",
              "\n",
              "  vsa_enroll_after6_transfer  vsa_enroll_elsewhere_after6_transfer  \\\n",
              "0                       17.2                                  11.1   \n",
              "1                        NaN                                   NaN   \n",
              "2                        NaN                                   NaN   \n",
              "3                        0.0                                   0.0   \n",
              "4                        NaN                                   NaN   \n",
              "\n",
              "                                             similar  state_sector_ct  \\\n",
              "0  232937|100724|405997|113607|139533|144005|2285...               13   \n",
              "1  196060|180461|201885|145600|209542|236939|1268...               13   \n",
              "2  217925|441511|205124|247825|197647|221856|1353...               16   \n",
              "3  232186|133881|196103|196413|207388|171128|1900...               13   \n",
              "4  100654|232937|242617|243197|144005|241739|2354...               13   \n",
              "\n",
              "   carnegie_ct  counted_pct  nicknames  cohort_size  \n",
              "0          386      99.7|07        NaN        882.0  \n",
              "1          106      56.0|07        UAB       1376.0  \n",
              "2          252     100.0|07        NaN          3.0  \n",
              "3          106      43.1|07        UAH        759.0  \n",
              "4          386      88.0|07        ASU       1351.0  \n",
              "\n",
              "[5 rows x 63 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cab2021-fa61-4842-9160-15b3add9a3e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>unitid</th>\n",
              "      <th>chronname</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>level</th>\n",
              "      <th>control</th>\n",
              "      <th>basic</th>\n",
              "      <th>hbcu</th>\n",
              "      <th>flagship</th>\n",
              "      <th>...</th>\n",
              "      <th>vsa_grad_after6_transfer</th>\n",
              "      <th>vsa_grad_elsewhere_after6_transfer</th>\n",
              "      <th>vsa_enroll_after6_transfer</th>\n",
              "      <th>vsa_enroll_elsewhere_after6_transfer</th>\n",
              "      <th>similar</th>\n",
              "      <th>state_sector_ct</th>\n",
              "      <th>carnegie_ct</th>\n",
              "      <th>counted_pct</th>\n",
              "      <th>nicknames</th>\n",
              "      <th>cohort_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>100654</td>\n",
              "      <td>Alabama A&amp;M University</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>4-year</td>\n",
              "      <td>Public</td>\n",
              "      <td>Masters Colleges and Universities--larger prog...</td>\n",
              "      <td>X</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>36.4</td>\n",
              "      <td>5.6</td>\n",
              "      <td>17.2</td>\n",
              "      <td>11.1</td>\n",
              "      <td>232937|100724|405997|113607|139533|144005|2285...</td>\n",
              "      <td>13</td>\n",
              "      <td>386</td>\n",
              "      <td>99.7|07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>882.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>100663</td>\n",
              "      <td>University of Alabama at Birmingham</td>\n",
              "      <td>Birmingham</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>4-year</td>\n",
              "      <td>Public</td>\n",
              "      <td>Research Universities--very high research acti...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>196060|180461|201885|145600|209542|236939|1268...</td>\n",
              "      <td>13</td>\n",
              "      <td>106</td>\n",
              "      <td>56.0|07</td>\n",
              "      <td>UAB</td>\n",
              "      <td>1376.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>100690</td>\n",
              "      <td>Amridge University</td>\n",
              "      <td>Montgomery</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>4-year</td>\n",
              "      <td>Private not-for-profit</td>\n",
              "      <td>Baccalaureate Colleges--Arts &amp; Sciences</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>217925|441511|205124|247825|197647|221856|1353...</td>\n",
              "      <td>16</td>\n",
              "      <td>252</td>\n",
              "      <td>100.0|07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>100706</td>\n",
              "      <td>University of Alabama at Huntsville</td>\n",
              "      <td>Huntsville</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>4-year</td>\n",
              "      <td>Public</td>\n",
              "      <td>Research Universities--very high research acti...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>232186|133881|196103|196413|207388|171128|1900...</td>\n",
              "      <td>13</td>\n",
              "      <td>106</td>\n",
              "      <td>43.1|07</td>\n",
              "      <td>UAH</td>\n",
              "      <td>759.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>100724</td>\n",
              "      <td>Alabama State University</td>\n",
              "      <td>Montgomery</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>4-year</td>\n",
              "      <td>Public</td>\n",
              "      <td>Masters Colleges and Universities--larger prog...</td>\n",
              "      <td>X</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100654|232937|242617|243197|144005|241739|2354...</td>\n",
              "      <td>13</td>\n",
              "      <td>386</td>\n",
              "      <td>88.0|07</td>\n",
              "      <td>ASU</td>\n",
              "      <td>1351.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 63 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cab2021-fa61-4842-9160-15b3add9a3e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cab2021-fa61-4842-9160-15b3add9a3e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cab2021-fa61-4842-9160-15b3add9a3e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.3 (1 Point)**: Create a cross table with the variables `control` and `level`. Make the table such that the each entry represents the *proportion* of observations rather than the count."
      ],
      "metadata": {
        "id": "5JXbfru6HGY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.3 Answer Here\n",
        "cross_tab = pd.crosstab(df['control'], df['level'], normalize=True)\n",
        "print(cross_tab)"
      ],
      "metadata": {
        "id": "Ja7cgbS9HWnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ac9b49-282e-46c9-d7c8-6edf5b22276e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "level                     2-year    4-year\n",
            "control                                   \n",
            "Private for-profit      0.122433  0.138757\n",
            "Private not-for-profit  0.017904  0.310690\n",
            "Public                  0.243813  0.166403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.4 (3 Points)**: Answer the following questions based on the cross table you created above:\n",
        "\n",
        "* What combination of `level` and `control` has the highest proportion of observations? What is the value for that proportion?:\n",
        "  - **Answer:**\n",
        "\n",
        "* What is the second most common combination of `level` and `control`? What is the value for that proportion?\n",
        "  - **Answer:**\n",
        "\n",
        "* What is the least common combination of `level` and `control`? What is the value for that proportion?\n",
        "  - **Answer:**"
      ],
      "metadata": {
        "id": "SuFG9fdeHkq9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.5 (2 Points)**: Look at the `grad_100_value` variable.\n",
        "  - What is the data type for the `grad_100_value` variable?\n",
        "  - Based on its data type, what kind of visualizations that we talked about in class could you make for it? Include all of the possible visualizations that we discussed in the EDA and Visualization notebooks that would make sense for the `grad_100_value` variable.\n",
        "\n",
        "**Answer:**\n"
      ],
      "metadata": {
        "id": "kZQRVLn0IYSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.5 Code Answer Here (for finding the data type)\n"
      ],
      "metadata": {
        "id": "AuLa9p-E6LKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.6 (3 Points)**:\n",
        "  - Based on your response above, create each of the potentiatl plots you identified for the `grad_100_value` variable.\n",
        "  - For each plot, describe the benefit of that visualization technique in comparison to the others you created. In other words, why would you want to use one visualization technique instead of another?\n",
        "\n",
        "  **Answer Here with Benefits of Each Visualization:**"
      ],
      "metadata": {
        "id": "1t36IKTMIrhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.6 Visualizations Here\n"
      ],
      "metadata": {
        "id": "5W9obBKaJ3t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.7 (1 Point)**: For the `grad_100_value` variable, create a Kernel Density Plot that is grouped by `control`. Based on this plot, what type of `control` seems to have the best (highest) graduation rates?\n",
        "\n",
        "**Answer Here**:"
      ],
      "metadata": {
        "id": "LpRXr5A6KMvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.7 Answer Here\n"
      ],
      "metadata": {
        "id": "kcxCXGH0Kql0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.8 (1 Point)**: For the `grad_100_value` variable, create a Kernel Density Plot that is grouped by `level`. Based on the plot, what `level` (4-year or 2-year) seems to have the highest graduation rates?\n",
        "\n",
        "**Answer Here:**"
      ],
      "metadata": {
        "id": "z3sbx_FpKmxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.8 Answer Here\n"
      ],
      "metadata": {
        "id": "pvm3LD4BK7_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.9 (1 Point)**: Generate the grouped statistical descriptions of `grad_100_value` by `level`.\n",
        "  - (Hint: use `.describe()` and `.groupby()`)"
      ],
      "metadata": {
        "id": "55JcwYRPK-Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.9 Answer Here\n"
      ],
      "metadata": {
        "id": "jgxc9fdkL67P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.10 (1 Point)**: Generate the grouped statistical descriptions of `grad_100_value` by `control`.\n",
        "  - (Hint: use `.describe()` and `.groupby()`)"
      ],
      "metadata": {
        "id": "jgTxRV8PL7i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.10 Answer Here\n"
      ],
      "metadata": {
        "id": "uqEWmvMGME3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.11 (2 Points)**:\n",
        "  - Using your grouped descriptions, which `level` of institutions has the highest average graduation rates?\n",
        "  - Which type of `control` has the highest average graduation rate?\n",
        "\n",
        "**Answer:**\n"
      ],
      "metadata": {
        "id": "Vi5dVCxUMFmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.12 (1 Point)**: Does your answer to **Q1.11** agree with your answers from **Q1.7** and **Q1.8**?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "5DwL2tt9M8aG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.13 (2 Points)**:\n",
        "\n",
        "1. Create a new variable, `df['levelXcontrol']=df['level']+', '+df['control']` that interacts `level` and `control`.\n",
        "\n",
        "1. Make a grouped kernel density plot of `grad_100_value` grouped by the new variable you created.\n",
        "\n",
        "1. Add reasonable labels for the x-axis, title, and legend of your grouped KDE Plot. *Hint:* You can change the legend title as an argument in the `sns.move_legend()` function. Look at the documentation for `sns.move_legend()`.\n",
        "\n",
        "1. Generate the grouped statistical descritions of `grad_100_value` grouped by your new variable.\n",
        "\n",
        "1. From you visualization and statistical descriptions, which institutions (combination of level and control) appear to have the best graduation rates? Which combination has the the worst graduation rates?\n",
        "\n",
        "**Answer:**\n"
      ],
      "metadata": {
        "id": "HkeZBSKgNeG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer 1.13 Here\n"
      ],
      "metadata": {
        "id": "SB55txNiNdiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.14 (1 Point)**: Create a scatterplot of the `grad_100_value` variable and `aid_value`. Place `aid_value` on the x-axis and `grad_100_value` on the y-axis. Add reasonable labels for the x-axis, y-axis, and title."
      ],
      "metadata": {
        "id": "L36lPPD9OBmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.14 Answer Here\n"
      ],
      "metadata": {
        "id": "3PIjFkmoOTaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.15 (2 Points)**: Calculate the covariance and correlation matrix between `grad_100_value` and `aid_value`."
      ],
      "metadata": {
        "id": "S97BjhyeOUnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.15 Answer Here\n"
      ],
      "metadata": {
        "id": "m6CiiDkGOU-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.16 (1 Point)**:\n",
        "  - From the scatterplot and matrices you created, what relationship do you see?\n",
        "  - Is there a positive or negative relationship between the two variables?\n",
        "  - How strong is it? Hint: Look at the correlation value for sign and strength.\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "GnAfZlx-Ocxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.17 (1 Point)**: Re-create your scatter plot of `grad_100_value` and `aid_value`. This time, change the color of the points based on the `control` variable. For which kinds of institutions does aid seem to have the strongest correlation with graduation rates?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "T29xUlZMO0mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.17 Answer Here\n"
      ],
      "metadata": {
        "id": "3_4umhabPM4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: K Nearest Neighbors (60 Points Total)\n",
        "\n",
        "### Question 2"
      ],
      "metadata": {
        "id": "XOGRaxZuEFcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.1 (2 Points)**: What is the difference between regression and classification?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "9s7CbTjiPjO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.2 (2 Points)**: What is a confusion table? What does it help us understand about a model's performance?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "wN1-RKsjPpeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.3 (2 Points)**: What does the SSE quantify about a particular model?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "jCPHDazjPtEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.4 (2 Points)**: What are overfitting and underfitting?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "RQ0tCdZXP0Mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.5 (2 Points)**: Why does splitting the data into training and testing sets, and choosing by evaluating accuracy or SSE on the test set, improve model performance?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "CwVwSzspP4Nc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.6 (2 Points)**: With classification, we can report a class label as a prediction or a probability distribution over class labels. Please explain potential strengths and weaknesses of each approach.\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "fD0zMSa0P8x8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n",
        "\n",
        "For this question, you will create a $k$ nearest neighbor regression model for the `USA_cars_datasets.csv` data. The data can be found on the GitHub repository for the class in the `assignments/data/` folder. The target variable `y` is `price` and the features are `year` and `mileage`."
      ],
      "metadata": {
        "id": "LTjzeiwnRZdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.1 (2 Points)**:\n",
        "\n",
        "- Load the `USA_cars_datasets.csv` data set. Call the data frame `cars_df`.\n",
        "- Keep the following variables and drop the rest: `price`, `year`, `mileage`.\n",
        "- Look at the data using head and report the dimensions (num rows, num columns) of the data. Print both values to the screen.\n",
        "- Are there any `NA`'s to handle? Include your answer as comment in your code near where you answer this question."
      ],
      "metadata": {
        "id": "myb5Lt6TRpWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Answer here\n",
        "\n"
      ],
      "metadata": {
        "id": "x8r61xupEFjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.2 (2 Points)**:  MaxMin normalize the `year` and `mileage` variables. First create them as columns in the `cars_df` data frame. Next, isolate these scaled columns in a new data frame called `X`."
      ],
      "metadata": {
        "id": "gCPF-zqeS4mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2 Answer here\n"
      ],
      "metadata": {
        "id": "QQVrM1aMTNq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.3 (2 Point)**: Split your data set into a 70/30 split, where 70% of the data are in the training data set and 30% are in the test data set. Use a random state seed of `100` for replicability."
      ],
      "metadata": {
        "id": "Q-sPpbZkTN0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.3 Answer here\n"
      ],
      "metadata": {
        "id": "H_G10vneTivj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.4 (5 Points)**:\n",
        "\n",
        "- Train a KNN model using your training data to predict predict `price` using `year` and `mileage`. Investigate the following values of $k$: $k=3,10,25,50,100,300$.\n",
        "\n",
        "- For each value of $k$, compute the mean squared error for the train and test data and save these values in a list for later.\n",
        "\n",
        "- As well, for each value of $k$ create a scatterplot showing the true value of `price` in the **test** dataset against the predicted value of `price`.\n",
        "  - In the title for each plot, inlcude the value of k and the calculated MSE.\n",
        "  - Set the ylimit and xlimit for each plot to be between [-100, 62000]. You can do this using `plt.xlim([-100, 62000])` and `plt.ylim([-100, 62000])` after you have created the scatter plot.\n",
        "  - Make sure to use `plt.show()` each time you are done creating a plot for that value of $k$."
      ],
      "metadata": {
        "id": "e1Wu0VVwTjD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.4 Answer here\n"
      ],
      "metadata": {
        "id": "36zMlZ0nTjTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.5 (2 Points)**: From the generated plots above, what patterns do you notice as you increase the value of $k$? Hint: what happens to our predictions?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "8A3P2-_WVDFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.6 (3 Points)**: Using your saved values of the MSE for the train and test data, plot both as line plots for different values of k. What does this plot show?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "7QkfB8xLVJZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.6 Answer here\n"
      ],
      "metadata": {
        "id": "tlZUD_ItVmxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.7 (2 Points)**\n",
        "  - What is the optimal value of $k$ from the $k$'s the we have investigated? Create a variable `best_k` that stores the best value of k and print it to the screen.\n",
        "  - Which subset of data did you use to determine the optimal value of $k$?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "KuF4VYwETw12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.7 Answer here\n"
      ],
      "metadata": {
        "id": "GEwchDtxZUhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.8 (5 Points)** Repeat the process from **Q3.4**. This time, investigate all possible values of k from 1 to 200.\n",
        "  - Do **NOT** make plots of the predicted vs actual values.\n",
        "  - Do make a plot that shows the train and test MSE for each value of $k$ this time. (MSE on the y-axis and $k$ on the x-axis.)\n",
        "  - Identify the best value of k from this new set of all possible values of $k$. Again, print the best value of to the screen."
      ],
      "metadata": {
        "id": "Jrvn_yKvaGVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.8 Answer Here\n"
      ],
      "metadata": {
        "id": "DSeT8V1maXTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.9 (2 Points)**: Now that we know how the model is performing across different values of $k$, revisit the plots that you created in **Q3.5**.\n",
        "   - Describe what happened in the plots of predicted versus actual prices in the test set as $k$ varied (Hint: Use the words \"underfitting\" and \"overfitting\".)\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "YlkP90AsT9bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4\n",
        "\n",
        "This is a case study on $k$ nearest neighbor classification, using the `zoo.csv` data.\n",
        "\n",
        "The data consist of a label, `class`, taking integer values 1 to 7, the name of the species, `animal`, and 16 characteristics of the animal, including `hair`, `feathers`, `milk`, `eggs`, `airborne`, and so on."
      ],
      "metadata": {
        "id": "F3-8ilreWM0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.1 (2 Points)**: Load the data as data frame: `zoo_df`.\n",
        "  - `For` each of the seven `class` labels, print the unique `animal` values in that class.\n",
        "  - This will help you get a sense of what is included in that group.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5Pe_Ss1UW9r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1 Answer Here\n"
      ],
      "metadata": {
        "id": "bpdM06RJXmhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.2 (2 Points)**: Additional EDA:\n",
        "  - How many observations are there for each of the `class` values?\n",
        "  - If you make a histogram, how many bins should you use?\n",
        "  - Does it look like there's an even split among the classes?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "Pwr5XQowXmZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2 Answer here\n"
      ],
      "metadata": {
        "id": "jk__LTgYXdei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.3 (2 Points)**: Additional EDA:\n",
        "  - How much variation is there in each of the features/covariates? Look at the distribution of any of the features you find interesting.\n",
        "  - Visualize the distirbution of at least 2 features."
      ],
      "metadata": {
        "id": "Q6BozRSBXvaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3 Answer Here\n"
      ],
      "metadata": {
        "id": "kOc-6vOrXvhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.4 (2 Points)**: We want to predict the `class` for each observation using a KNN Classifier.\n",
        "  - Split your data into your outcome (y) and features (X).\n",
        "  - Remove any non-numeric data from your features.\n",
        "  - Split the data 50/50 into training and test/validation sets. Use a random state of 10 for replicability. (The smaller the data are, the more equal the split should be. Otherwise, all of the members of one class end up in the training or test data, and the model falls apart.)"
      ],
      "metadata": {
        "id": "UhAbmPVKXPKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.4 Answer Here\n"
      ],
      "metadata": {
        "id": "8FBWRBs0Wxpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.5 (5 Points)**: Using all of the numeric variables, build a $k$-NN classifier.\n",
        "  - Given your training data, what is the largest value of $k$ that you can test? Look at all values of $k$ from 1 to your identified max value.\n",
        "  - From these values of $k$, identify the best value of $k$. How did you identify the best value of $k$?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "itUnJiQQXUPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.5 Answer Here\n"
      ],
      "metadata": {
        "id": "HTYXQcgoXVPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.6 (3 Points)**:\n",
        "  - Print a confusion table for the optimal model, comparing predicted and actual class label on the test set. Keep the table as raw counts.\n",
        "  - How accurate is your optimal model?\n",
        "  - Which true classe(s) are we misclassifying?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "oQpWs8r8XVqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.6 Answer Here\n"
      ],
      "metadata": {
        "id": "SjIIMcEuXVys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.7 (5 Points)**: Use only `milk`, `aquatic`, and `airborne` to train a new $k$-NN classifier.\n",
        "  - Find the optimal model and print your confusion table for the optimal model.\n",
        "  - Does your optimal model predict all possible classes? If not, what possible classes does it not predict?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "5WOJrf2pXayF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.7 Answer Here\n"
      ],
      "metadata": {
        "id": "JDNw6bAJXazi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.8 (2 Points)** Using your optimal model, we want to know if it gives any chance to the classes that aren't being predicted right now.\n",
        "  - To see the underlying probabilities for the test observations, use `model.predict_proba(X_test)` to predict probabilities rather than labels for your `X_test` test data for your fitted `model`.\n",
        "  - Look at the plot that is created below. It is a heatmap where the class index is the columns and each row is an observation. The color indicates the probability that the model is assigning to a given class index.\n",
        "  - Are all of the classes represented when we look at the probabilities instead of hard classifications? Explain your results.\n",
        "  - Using this information, why might we want to look at the probabilities instead of the hard classification?\n",
        "\n",
        "  **Answer:**"
      ],
      "metadata": {
        "id": "XTsEassnr72B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.8 Answer Here\n",
        "\n",
        "# Fill in your predicted probabilities here\n",
        "predicted_proabilities =\n",
        "\n",
        "# Create a heatmap of the predicted probabilities per class\n",
        "sns.heatmap(predicted_proabilities, cmap = 'plasma', cbar_kws={'label': 'Predicted Probability for Class'})\n",
        "plt.xlabel('Class Index')\n",
        "plt.ylabel('Class Observation')\n",
        "plt.title('Heatmap of the Predicted Class Probability\\nfor each Test Observation')\n",
        "plt.xticks(np.arange(zoo_df['class'].unique().shape[0]) + 0.5, np.arange(zoo_df['class'].unique().shape[0]) + 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EASz0u6cr8QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Clustering (15 Points Total)"
      ],
      "metadata": {
        "id": "8gZBWFD8EFzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5\n",
        "\n",
        "For this question, we want to investigate how the K Means Clustering model performs as our data becomes either less or more noisey."
      ],
      "metadata": {
        "id": "QQcG_V8C0wV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.0** Run the code below to create a function `createData`. This function will create data with 3 different clusters (i.e. data generation processes). This is done by changing the mean of the normal distribution. We can make the difference between the data sets less detectable by increasing the `noise` which is just the standard deviation of each distribution."
      ],
      "metadata": {
        "id": "awhVAWUF07I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a function that creates data with varying level of noise\n",
        "# This noise is just the standard deviation\n",
        "# This function returns a dataframe with the generated data\n",
        "\n",
        "def createData(noise, N=50, seed = 100):\n",
        "    # Set the seed for replicability\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Generate (x1,x2,g) triples:\n",
        "    X1 = np.array([\n",
        "        np.random.normal(1,noise,N), # Group one has x with mean 1\n",
        "        np.random.normal(1,noise,N)  # Group one has y with mean 1\n",
        "    ])\n",
        "\n",
        "    X2 = np.array([\n",
        "        np.random.normal(3,noise,N), # Group two has x with mean 3\n",
        "        np.random.normal(2,noise,N)  # Group two has x with mean 2\n",
        "    ])\n",
        "\n",
        "    X3 = np.array([\n",
        "        np.random.normal(5,noise,N), # Group three has x with mean 5\n",
        "        np.random.normal(3,noise,N)  # Group three has x with mean 3\n",
        "    ])\n",
        "\n",
        "    # Concatenate the data into one data frame\n",
        "    gdf1 = pd.DataFrame({'x1':X1[0,:],'x2':X1[1,:],'group':'a'})\n",
        "    gdf2 = pd.DataFrame({'x1':X2[0,:],'x2':X2[1,:],'group':'b'})\n",
        "    gdf3 = pd.DataFrame({'x1':X3[0,:],'x2':X3[1,:],'group':'c'})\n",
        "    df = pd.concat([gdf1,gdf2,gdf3],axis=0)\n",
        "\n",
        "    # Retun the generate data\n",
        "    return df"
      ],
      "metadata": {
        "id": "In7-ZFFNEF9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.1 (2 Point)**:  Using the `createData` function, create 5 data sets with varying levels of noise values. The values of noise and what you should call the data frames are included in the table below:\n",
        "\n",
        "| Data Frame Name | Noise Value |\n",
        "| --------------- | ----------- |\n",
        "| `df0_125` | 0.125 |\n",
        "| `df0_25` | 0.25 |\n",
        "| `df0_5` | 0.5 |\n",
        "| `df1_0` | 1.0 |\n",
        "| `df2_0` | 2.0 |"
      ],
      "metadata": {
        "id": "Q2h3AIgW2srD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 Answer Here\n"
      ],
      "metadata": {
        "id": "UnciFo5i1k4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.2 (2 Point)**:  Create scatter points of the `x1` and `x2` for each of your data sets and color the points based on the `group` variable.\n",
        "  - For each plot, change the title so that it reflects what the value of noise is.\n",
        "  - What do you notice happens to the visual distinctness of the clusters as you increase the noise level from 0.125 to 2?\n",
        "  - When do the clusters begin to not be clear without the included coloring of the dots?\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "aSNtRSM-3fsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2 Answer Here\n"
      ],
      "metadata": {
        "id": "Uiu5Mc0S3dNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.3 (6 Points)**:  \n",
        "- For each of the generated data sets, run K Means Clustering on the data set and generate a scree plot.\n",
        "- For each plot, set the ylmit to be between 0 and 35 (`plt.ylim([0, 35])`).\n",
        "-  So that you can re-use this code for each data set instead of re-writing it, create a function called `GenerateScreePlot()` that takes your data and the noise as input.\n",
        "- So that your results are reproducible, use the following values for the parameters in your analysis:\n",
        "  - `max_k`: 15\n",
        "  - `max_iter`: 300\n",
        "  - `n_init`: 10\n",
        "  - `random_state`: 0"
      ],
      "metadata": {
        "id": "AxhcNPCx5PB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.3 Answer Here\n"
      ],
      "metadata": {
        "id": "LfzDnJFU4YWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.4 (2 Points)**:  \n",
        "- From the plots you generated, what happens to the scree plot as the noise increases?\n",
        "- What happens to your ability to identify the elbow, or optimal value of k, as the noise increases?\n",
        "\n",
        "**Answer Here:**"
      ],
      "metadata": {
        "id": "Ep7qjRYa8HIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.5 (3 Point)**:  Given the example you ran, explain the intuition about using the elbow method with the scree plot. Discuss when the approach will work vs when it will not work.\n",
        "\n",
        "**Answer:**"
      ],
      "metadata": {
        "id": "p8zltLcn8w8d"
      }
    }
  ]
}